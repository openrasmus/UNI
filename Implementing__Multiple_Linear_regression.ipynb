{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementing _Multiple_Linear_regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_o6AEU_3HAX"
      },
      "source": [
        "# Project: day 1\r\n",
        "**Goal:**  Implement linear regression in python from scratch, and understand how sklearn has implemented linear regression. To do this:\r\n",
        "\r\n",
        "1.   Implement linear regression with sklearn.\r\n",
        "2.   Estimate coefficents and intercept without sklearn to find out how to do linear regresion without a library.\r\n",
        "3.  Check that the results in 1. and 2. are roughly equal\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "**Metric**: Infinity norm of difference between implementation in 1. and 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbyvA1v8ekaI"
      },
      "source": [
        "from sklearn.datasets import load_boston\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "import numpy as np"
      ],
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XORw1cA2fCOs"
      },
      "source": [
        "predictors, response = load_boston(return_X_y=True)\r\n",
        "index = int(len(predictors)*0.8)\r\n",
        "\r\n",
        "\r\n",
        "#Split data 80/20 into train/test  \r\n",
        "train_x = predictors[:index]\r\n",
        "train_y = response[:index]\r\n",
        "test_x = predictors[index:]\r\n",
        "test_y = response[index:]"
      ],
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo-2_hp-iUtY"
      },
      "source": [
        "#Test for model\r\n",
        "model = LinearRegression().fit(train_x, train_y)\r\n",
        "y_pred = model.predict(test_x)\r\n",
        "\r\n",
        "intercept_test = model.intercept_\r\n",
        "coef_test = model.coef_\r\n",
        "mse_test = mean_squared_error(test_y,y_pred)\r\n",
        "r_sq_test = model.score(test_x,test_y)\r\n",
        "\r\n",
        "#calculates find the elemen which maximizes |a_i-b_i|\r\n",
        "def difference_infinity_norm(a,b):\r\n",
        "  difference = np.absolute(a-b)\r\n",
        "  max_element = max(difference)\r\n",
        "  return(max_element)"
      ],
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1hsCHPbkylt",
        "outputId": "fbe1a9cb-89a2-4c38-bc20-e16960c67f82"
      },
      "source": [
        "#Check if coeficenst are given by\r\n",
        "#The maximum likelihood estimator of the coffeficents\r\n",
        "n,m = np.shape(train_x)\r\n",
        "inverse = np.linalg.solve((train_x.T@train_x),np.identity(13))\r\n",
        "B = inverse@train_x.T@train_y\r\n",
        "print(\"Max norm of sklearn models prediction minus my own implementation with intercept:\", difference_infinity_norm(B,coef_test))\r\n",
        "#Error is quite large, so guessing the default parameters is using a design matrix\r\n",
        "#help(model) show a parameter fit_intercept=bool, default = True\r\n",
        "#check if setting this to False is equivalent to this approach:\r\n",
        "model_no_intercept = LinearRegression(fit_intercept=False).fit(train_x, train_y)\r\n",
        "coef_without_intercept = model_no_intercept.coef_\r\n",
        "#Test fails despite both being almost identical\r\n",
        "print(\"Max norm of sklearn models prediction minus my own implementation without intercept:\", difference_infinity_norm(B,coef_without_intercept))\r\n",
        "#Guessing this due to difference in precision\r\n",
        "#Biggest error is realtively small at ~10^-{12}, but this confirms how \r\n",
        "#fit_intercept works!"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max norm of sklearn models prediction minus my own implementation with intercept: 13.215563883313086\n",
            "Max norm of sklearn models prediction minus my own implementation without intercept: 3.955502592134508e-12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8VEz4_H0e6S",
        "outputId": "9de5e9f4-0ce1-42cd-8507-93c486a94dd0"
      },
      "source": [
        "#Straightforward implementation is not the same due to not including the incetercept\r\n",
        "#Add a column of ones to find intercept!\r\n",
        "def create_design_matrix_lm(numpy_array):\r\n",
        "  n,m = np.shape(numpy_array)\r\n",
        "  column_of_ones = np.ones([n,1])\r\n",
        "  design_matrix = np.c_[column_of_ones ,numpy_array]\r\n",
        "  return(design_matrix)\r\n",
        "\r\n",
        "design = create_design_matrix_lm(train_x)\r\n",
        "n,m = np.shape(design)\r\n",
        "inverse = np.linalg.solve((design.T@design),np.identity(m))\r\n",
        "B = inverse@design.T@train_y\r\n",
        "print(\"Max norm of sklearn models coefficents minus my implementation's coefficents with a design matrix:\" ,difference_infinity_norm(B[1:],coef_test))\r\n",
        "print(\"Max norm of difference between intercepts:\", np.abs(B[0]-model.intercept_))\r\n"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max norm of sklearn models coefficents minus my implementation's coefficents with a design matrix: 1.7358559034619248e-11\n",
            "Max norm of difference between intercepts: 3.453948238529847e-11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUJolnpO6Nyw",
        "outputId": "219ba589-1380-4ba4-c874-24165675bf7f"
      },
      "source": [
        "def fit(B,x):\r\n",
        "  X = create_design_matrix_lm(x)\r\n",
        "  return(np.dot(X,B))\r\n",
        "\r\n",
        "def mse(y,y_pred):\r\n",
        "  sum = 0\r\n",
        "  for i in range(len(y)):\r\n",
        "    sum += (y[i]-y_pred[i])**2\r\n",
        "  return(sum/len(y))\r\n",
        "\r\n",
        "def rss(y,y_pred):\r\n",
        "  yhat = np.sum(y)/len(y)\r\n",
        "  SStot = 0\r\n",
        "  SSres = 0\r\n",
        "  for i in range(len(y)):\r\n",
        "    SSres += (y[i]-y_pred[i])**2\r\n",
        "    SStot += (y[i]-yhat)**2\r\n",
        "  return(1-(SSres/SStot))\r\n",
        "\r\n",
        "y_pred = fit(B,test_x)\r\n",
        "print(\"Norm of MSE's\", mse_test-mse(test_y,y_pred))\r\n",
        "print(\"Norm of R squared:\" , np.abs(rss(test_y,y_pred)-r_sq_test))"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Norm of MSE's -1.0587086762825493e-12\n",
            "Norm of R squared: 3.977373985719623e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmUFHP705slY"
      },
      "source": [
        "#Results: \r\n",
        "The max norm of the difference between sklearns predictions, and the predictions i got with my own implementation were smaller than $10^{-11}$"
      ]
    }
  ]
}